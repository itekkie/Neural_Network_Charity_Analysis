# Neural Network Charity Analysis. Project 19 of the UofT.
## `-Contents-`	
	
- [Overview of the Neural Network Charity Analysis](#Overview-of-the-Credit-Risk-Analysis)	
- [Resources](#resources)	
- [The Neural Network Charity Analysis Result](#The-Neural-Network-Charity-Analysis-Result)
  - [Preprocessing Data for a Neural Network Model](#--Preprocessing-Data-for-a-Neural-Network-Model)
  - [Compile, Train, and Evaluate the Model](#--Compile,-Train,-and-Evaluate-the-Model)
  - [Optimize the Model](#--Optimize-the-Model)
- [The Neural Network Charity Analysis Summary](#The-Neural-Network-Charity-Analysis-Summary)
## `Overview of the Neural Network Charity Analysis`	
	
The purpose for the project is to create a binary classifier that is capable of predicting whether applicants will be successful if funded by Alphabet Soup.

The analysis consists of three technical analysis deliverables and a written report as the following: 

- Preprocessing Data for a Neural Network Model;
- Compile, Train, and Evaluate the Model;
- Optimize the Model;
- Submit a Written Report on the Neural Network Model.
## `Resources`	
The analysis is created using next software: Jupyter-notebook 6.3.0, Python 3.8.8, Pandas 1.2.4, machine learning libraries for Python: tensorflow, scikit-learn 0.24.1, Visual Studio Code 1.58.0.

## `The Neural Network Charity Analysis Result`
### `- Preprocessing Data for a Neural Network Model`	

Preprocessing the dataset in order to compile, train, and evaluate the neural network model later in Deliverable 2d.

The result of Preprocessing Data for a Neural Network Model can be found in the [AlphabetSoupCharity](./AlphabetSoupCharity.ipynb) file.

According

Data Preprocessing
What variable(s) are considered the target(s) for your model?
What variable(s) are considered to be the features for your model?
What variable(s) are neither targets nor features, and should be removed from the input data?



### `- Compile, Train, and Evaluate the Model`

Using your knowledge of TensorFlow, you’ll design a neural network, or deep learning model, to create a binary classification model that can predict if an Alphabet Soup–funded organization will be successful based on the features in the dataset. You’ll need to think about how many inputs there are before determining the number of neurons and layers in your model. Once you’ve completed that step, you’ll compile, train, and evaluate your binary classification model to calculate the model’s loss and accuracy

The result of the Compile, Train, and Evaluate the Model can be found in the [AlphabetSoupCharity](./AlphabetSoupCharity.ipynb) file.

How many neurons, layers, and activation functions did you select for your neural network model, and why?
Were you able to achieve the target model performance?
What steps did you take to try and increase model performance?

### `- Optimize the Model`

Using your knowledge of TensorFlow, optimize your model in order to achieve a target predictive accuracy higher than 75%. If you can't achieve an accuracy higher than 75%, you'll need to make at least three attempts to do so.

NOTE
The accuracy for the solution is designed to be lower than 75% after completing the requirements for Deliverables 1 and 2.

Optimize your model in order to achieve a target predictive accuracy higher than 75% by using any or all of the following:

Adjusting the input data to ensure that there are no variables or outliers that are causing confusion in the model, such as:
Dropping more or fewer columns.
Creating more bins for rare occurrences in columns.
Increasing or decreasing the number of values for each bin.
Adding more neurons to a hidden layer.
Adding more hidden layers.
Using different activation functions for the hidden layers.
Adding or reducing the number of epochs to the training regimen


The result of the Ensemble Classifier algorithm can be found in the [AlphabetSoupCharity_Optimzation](./AlphabetSoupCharity_Optimzation.ipynb) file.

## `The Neural Network Charity Analysis Summary`

Summarize the overall results of the deep learning model. Include a recommendation for how a different model could solve this classification problem, and explain your recommendation.

According the results of machine learning models 


Additionally, 
